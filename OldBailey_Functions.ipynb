{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from ngramsapi import get_word_trends\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_list = [{\n",
    "  \"type\": \"function\",\n",
    "  \"function\": {\n",
    "    \"name\": \"get_word_trends\",\n",
    "    \"description\": \"Get the trends of a word over time using the google ngrams api\",\n",
    "    \"parameters\": {\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": {\n",
    "        \"query\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"The word to get the trends for\"\n",
    "        },\n",
    "        \"start_year\": {\n",
    "          \"type\": \"integer\",\n",
    "          \"description\": \"The start year for the trends\"\n",
    "        },\n",
    "        \"end_year\": {\n",
    "          \"type\": \"integer\",\n",
    "          \"description\": \"The end year for the trends\"\n",
    "        },\n",
    "        \"corpus\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"The corpus to use for the trends\"\n",
    "        },\n",
    "        \"smoothing\": {\n",
    "          \"type\": \"integer\",\n",
    "          \"description\": \"The smoothing factor for the trends\"\n",
    "        },\n",
    "        \"case_insensitive\": {\n",
    "          \"type\": \"boolean\",\n",
    "          \"description\": \"Flag to indicate if the search should be case insensitive\"\n",
    "        },\n",
    "      },\n",
    "      \"required\": [\"query\"]\n",
    "    }\n",
    "    \n",
    "  }\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.retrieve(assistant_id=os.getenv(\"OPENAI_ASSISTANT_ID\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Assistant(id='asst_NPJ7zjXnm6ShHHw5RuCldZDF', created_at=1720033291, description=None, instructions='EVERY answer should start with the: trial ID, uri, year and date in list format:\\n- TrialAccount id\\n- collection\\n- uri\\n- year\\n- date\\n\\n1. Understanding the Old Bailey Database:\\nContext: The Old Bailey database contains records of criminal trials held at the Central Criminal Court in London, commonly known as the Old Bailey, from 1674 to 1913.\\nContent: The database includes detailed accounts of the proceedings, including the names of the accused, the charges, the verdicts, and the sentences.\\n\\n2. Query Structure:\\nSpecificity: Encourage users to be as specific as possible in their queries to facilitate efficient searches (e.g., specific dates, names, types of crime).\\nExamples:\\n\"Find all trials involving theft in 1782.\"\\n\"What was the verdict in the trial of John Doe in 1805?\"\\n\"List all female defendants tried for murder between 1800 and 1850.\"\\n\\n\\n3. Database Navigation:\\nSearch Filters: Use the search filters effectively:\\nDate Range: Filter by specific years or periods.\\nCrime Type: Filter by categories such as theft, murder, assault, etc.\\nVerdict: Filter by verdicts such as guilty, not guilty, etc.\\nDefendant Details: Filter by age, gender, or name.\\n\\n\\n4. Formulating Responses:\\nConciseness: Provide clear and concise answers. If the query results in a large number of records, summarize the key details.\\nDetails: Include relevant information such as:\\nDate of Trial: When the trial took place.\\nDefendant: Name, age, and gender of the defendant.\\nCrime: Description of the crime.\\nVerdict and Sentence: The outcome of the trial and any sentence given.\\nExamples:\\n\"In 1782, John Smith was tried for theft and found guilty. He was sentenced to transportation for seven years.\"\\n\"Mary Jones, a 25-year-old woman, was tried for murder in 1805 and acquitted.\"\\n\\n\\n5. Handling Ambiguities:\\nClarification Requests: If the query is ambiguous or too broad, ask for additional details to narrow down the search.\\nExample: \"Could you specify a date range or type of crime for the search?\"\\n\\n\\n6. Providing Context:\\nHistorical Context: Where relevant, provide brief historical context or explanations to help users understand the significance of certain trials or legal terms used during the period.\\nExample: \"Transportation was a common sentence during the 18th century, where convicts were sent to penal colonies in America or Australia.\"\\n\\n\\n7. Error Handling:\\nNo Results Found: Inform the user if no records match their query and suggest alternative search criteria.\\nExample: \"No trials were found for \\'John Doe\\' in 1805. Could you check the spelling of the name or provide a different date?\"\\n\\n\\n8. Multiple Matching records:\\nGive all accounts with date ranges and summaries\\n', metadata={}, model='gpt-3.5-turbo', name='Oldbailey DB + Functions', object='assistant', tools=[FunctionTool(function=FunctionDefinition(name='get_word_trends', description='Get the trends of a word over time using the google ngrams api', parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The word to get the trends for'}, 'start_year': {'type': 'integer', 'description': 'The start year for the trends'}, 'end_year': {'type': 'integer', 'description': 'The end year for the trends'}, 'corpus': {'type': 'string', 'description': 'The corpus to use for the trends'}, 'smoothing': {'type': 'integer', 'description': 'The smoothing factor for the trends'}, 'case_insensitive': {'type': 'boolean', 'description': 'Flag to indicate if the search should be case insensitive'}}, 'required': ['query']}), type='function')], response_format='auto', temperature=0.5, tool_resources=ToolResources(code_interpreter=None, file_search=None), top_p=1.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assistant\n",
    "client.beta.assistants.update(\n",
    "  assistant_id=assistant.id,\n",
    "  tools=tools_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler\n",
    "\n",
    "arguments = []\n",
    " \n",
    "class EventHandler(AssistantEventHandler):    \n",
    "  @override\n",
    "  def on_text_created(self, text) -> None:\n",
    "    print(f\"\\nassistant > \", end=\"\", flush=True)\n",
    "      \n",
    "  @override\n",
    "  def on_text_delta(self, delta, snapshot):\n",
    "    print(delta.value, end=\"\", flush=True)\n",
    "      \n",
    "  def on_tool_call_created(self, tool_call):\n",
    "    print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
    "  \n",
    "  def on_tool_call_delta(self, delta, snapshot):\n",
    "    if delta.type == \"function\":\n",
    "      print(delta.function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requires_action\n",
      "No tool outputs to submit.\n",
      "requires_action\n"
     ]
    }
   ],
   "source": [
    "threadId = \"\"\n",
    "\n",
    "message = client.beta.threads.messages.create(\n",
    "  thread_id=threadId,\n",
    "  role=\"user\",\n",
    "  content=\"Can you show me the trends for the word 'openai' from 2010 to 2020?\"\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "  thread_id=threadId,\n",
    "  assistant_id=assistant.id,\n",
    ")\n",
    "\n",
    "if run.status == 'completed': \n",
    "  messages = client.beta.threads.messages.list(\n",
    "    thread_id=threadId\n",
    "  )\n",
    "  print(messages)\n",
    "else:\n",
    "  print(run.status)\n",
    "  \n",
    "tool_outputs = []\n",
    "for tool in run.required_action.submit_tool_outputs.tool_calls:\n",
    "  if tool.function.name == \"get_current_temperature\":\n",
    "    tool_outputs.append({\n",
    "      \"tool_call_id\": tool.id,\n",
    "      \"output\": \"57\"\n",
    "    })\n",
    "  elif tool.function.name == \"get_rain_probability\":\n",
    "    tool_outputs.append({\n",
    "      \"tool_call_id\": tool.id,\n",
    "      \"output\": \"0.06\"\n",
    "    })\n",
    "\n",
    "# Submit all tool outputs at once after collecting them in a list\n",
    "if tool_outputs:\n",
    "  try:\n",
    "    run = client.beta.threads.runs.submit_tool_outputs_and_poll(\n",
    "      thread_id=threadId,\n",
    "      run_id=run.id,\n",
    "      tool_outputs=tool_outputs\n",
    "    )\n",
    "    print(\"Tool outputs submitted successfully.\")\n",
    "  except Exception as e:\n",
    "    print(\"Failed to submit tool outputs:\", e)\n",
    "else:\n",
    "  print(\"No tool outputs to submit.\")\n",
    " \n",
    "if run.status == 'completed':\n",
    "  messages = client.beta.threads.messages.list(\n",
    "    thread_id=threadId\n",
    "  )\n",
    "  print(messages)\n",
    "else:\n",
    "  print(run.status)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
